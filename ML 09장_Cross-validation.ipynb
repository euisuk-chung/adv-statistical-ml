{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing ###\n",
    "# Data Loading\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases'\n",
    "                 '/breast-cancer-wisconsin/wdbc.data', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X, y 변수 스케일링\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = df.loc[:, 2:].values  # 30개의 feature를 할당\n",
    "y = df.loc[:, 1].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)   # class [B, M]을 class [0, 1]로 전환\n",
    "le.classes_\n",
    "le.transform(['M', 'B'])  # 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6274165202108963\n"
     ]
    }
   ],
   "source": [
    "print(1-y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 data를 training data와 test data로 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,\n",
    "                                                    stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pipeline Streaming: 표준화 → PCA → Logistic Regression ###\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                        PCA(n_components=4),\n",
    "                        LogisticRegression(random_state=1, solver='lbfgs'))  # 적용 순서대로 나열\n",
    "pipe_lr.fit(X_train, y_train)            # 표준화(fit → transform) → PCA(fit → transform) → Logistic Reg fit의 순서로 처리\n",
    "y_train_pred = pipe_lr.predict(X_train)  # 표준화 transform → PCA transform → Logistic Reg prediction 순서로 처리\n",
    "y_test_pred = pipe_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967032967032967\n",
      "0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score\n",
    "print(pipe_lr.score(X_train, y_train))  # Training accuracy\n",
    "print(pipe_lr.score(X_test, y_test))    # Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.97826087 0.95652174 0.95652174 0.95652174 0.91304348 0.95555556\n",
      " 0.97777778 0.97777778 1.         0.97777778]\n",
      "CV accuracy: 0.965 +/- 0.022\n"
     ]
    }
   ],
   "source": [
    "### K-fold cross-validation using pipeline ###\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(estimator=pipe_lr, X=X_train, y=y_train, cv=10)  # Accuracy scores\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "\n",
    "import numpy as np\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Bias-variance trade-off 그래프로 확인하기 ###\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                        LogisticRegression(penalty='l2', random_state=1, solver='lbfgs'))\n",
    "train_sizes, train_scores, test_scores =\\\n",
    "             learning_curve(estimator=pipe_lr, X=X_train, y=y_train,\n",
    "                            train_sizes=np.linspace(0.1, 1.0, 10), cv=10)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5,\n",
    "         label='training accuracy')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std,\n",
    "                 alpha=0.15, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s',\n",
    "         markersize=5, label='validation accuracy')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8, 1.03])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9846153846153847\n",
      "{'svc__C': 100.0, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'}\n",
      "0.989010989010989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Grid search에 의한 초모수 결정 (SVM) ###\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "pipe_svc = make_pipeline(StandardScaler(), SVC(random_state=1))\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = [{'svc__C': param_range, 'svc__kernel': ['linear']},\n",
    "              {'svc__C': param_range, 'svc__gamma': param_range,\n",
    "               'svc__kernel': ['rbf']}]\n",
    "gs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid,\n",
    "                  scoring='accuracy', cv=10)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "\n",
    "clf = gs.best_estimator_\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train,y_train))\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy: 0.977 +/- 0.009\n"
     ]
    }
   ],
   "source": [
    "### Nested cross-validation을 이용한 초모수 결정 ###\n",
    "gs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid,\n",
    "                  scoring='accuracy', cv=3)\n",
    "scores = cross_val_score(gs, X, y, scoring='accuracy', cv=5)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy: 0.942 +/- 0.012\n"
     ]
    }
   ],
   "source": [
    "# Decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "inner_cv=KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "outer_cv=KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "gs = GridSearchCV(estimator=DecisionTreeClassifier(random_state=0),\n",
    "                  param_grid=[{'max_depth': [1, 2, 3, 4, 5, 6, 7, None]}],\n",
    "                  scoring='accuracy', cv=inner_cv)\n",
    "scores = cross_val_score(gs, X, y, scoring='accuracy', cv=outer_cv)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy: 0.912 +/- 0.021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "inner_cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "outer_cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "gs = GridSearchCV(estimator=DecisionTreeClassifier(random_state=0),\n",
    "                  param_grid=[{'max_depth': [1, 2, 3, 4, 5, 6, 7, None]}],\n",
    "                  scoring='accuracy', cv=inner_cv)\n",
    "scores = cross_val_score(gs, X, y, scoring='accuracy', cv=outer_cv)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
